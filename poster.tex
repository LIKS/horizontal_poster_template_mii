%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Multiplicative domain poster
% Created by Nathaniel Johnston
% August 2009
% http://www.nathanieljohnston.com/2009/08/latex-poster-template/
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[final]{beamer}
\usepackage[scale=1.24]{beamerposter}
\usepackage{graphicx}			% allows us to import images

%-----------------------------------------------------------
% Custom commands that I use frequently
%-----------------------------------------------------------

\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\cl}[1]{\mathcal{#1}}
\newcommand{\fA}{\mathfrak{A}}
\newcommand{\fB}{\mathfrak{B}}
\newcommand{\Tr}{{\rm Tr}}
\newtheorem{thm}{Theorem}

%-----------------------------------------------------------
% Define the column width and poster size
% To set effective sepwid, onecolwid and twocolwid values, first choose how many columns you want and how much separation you want between columns
% The separation I chose is 0.024 and I want 4 columns
% Then set onecolwid to be (1-(4+1)*0.024)/4 = 0.22
% Set twocolwid to be 2*onecolwid + sepwid = 0.464
%-----------------------------------------------------------

\newlength{\sepwid}
\newlength{\onecolwid}
\newlength{\twocolwid}
\setlength{\paperwidth}{48in}
\setlength{\paperheight}{36in}
\setlength{\sepwid}{0.024\paperwidth}
\setlength{\onecolwid}{0.22\paperwidth}
\setlength{\twocolwid}{0.464\paperwidth}
\setlength{\topmargin}{-0.5in}
\usetheme{confposter}
\usepackage{exscale}

%-----------------------------------------------------------
% The next part fixes a problem with figure numbering. Thanks Nishan!
% When including a figure in your poster, be sure that the commands are typed in the following order:
% \begin{figure}
% \includegraphics[...]{...}
% \caption{...}
% \end{figure}
% That is, put the \caption after the \includegraphics
%-----------------------------------------------------------

\usecaptiontemplate{
\small
\structure{\insertcaptionname~\insertcaptionnumber:}
\insertcaption}

%-----------------------------------------------------------
% Define colours (see beamerthemeconfposter.sty to change these colour definitions)
%-----------------------------------------------------------

\setbeamercolor{block title}{fg=jred,bg=white}
\setbeamercolor{block body}{fg=black,bg=white}
\setbeamercolor{block alerted title}{fg=white,bg=jred}
\setbeamercolor{block alerted body}{fg=black,bg=dred}

%-----------------------------------------------------------
% Name and authors of poster/paper/research
%-----------------------------------------------------------

\title{One-step worst-case optimal bivariate algorithm for \\bi-objective optimization}
\author{Albertas Gimbutas}
\institute{Institute of Mathematics and Informatics, University of Vilnius}

%-----------------------------------------------------------
% Start the poster itself
%-----------------------------------------------------------
% The \rmfamily command is used frequently throughout the poster to force a serif font to be used for the body text
% Serif font is better for small text, sans-serif font is better for headers (for readability reasons)
%-----------------------------------------------------------

\begin{document}
\begin{frame}[t]
  \begin{columns}[t]												% the [t] option aligns the column's content at the top
    \begin{column}{\sepwid}\end{column}			% empty spacer column
    \begin{column}{\onecolwid}
      \begin{alertblock}{Abstract}
        \rmfamily{Bivariate one-step worst-case optimal algorithm for
        bi-objective Lipschitz optimization problems is presented.
        The feasible region is partitioned by simplices. The bivariate algorithm is
        used to compute discreate Pareto front representation with predefined
        accuracy. The proposed algorithm is constructed by generalizing one-step
        worst-case optimal univariate algorithm for bivariate problems.
        Lipschitz condition with respect to Euclidean distance is used.}
      \end{alertblock}
      \vskip2ex

    \begin{block}{The problem}
        The problem of bivariate bi-objective non-convex optimization 
        \begin{equation}
            \min_{\textbf{x} \in A} f(\textbf{x}), \;\; f(\textbf{x}) =
            (f^1(\textbf{x}), f^2(\textbf{x}))^T, \;\; A \subset \mathbb{R}^2
        \end{equation}
    is considered, where the feasible region is bounded 
    \begin{equation}
        A = \{\textbf{x}: a_k \le x_k \le b_k, k=1,2\}
    \end{equation}
    \end{block}\vskip2ex

    \begin{block}{Lipschitz condition}
        Practical objective functions normally have bounded rate of change.
        Which allows the detection of the global minimum with a prescribed
        accuracy \cite{GlobalOptimization}.

        If a function $f(x)$ is in Lipschitz objective functions class $\Phi(L)$ then
        it has a constant bound $L$ on the first derivative. Lets say
        \begin{gather}
            \textbf{x} \in A \subset \mathbb{R}^d \\
            L = (L^1, ..., L^n),\;\; L^k > 0,\;\; k=1,...,n \\
            f(\textbf{x}) = (f^1(\textbf{x}), ..., f^n(\textbf{x})),\;\; f(\textbf{x}) \in \Phi(L)
        \end{gather}
        and $A$ is bounded, then the Lipschitz condition holds:
        \begin{equation}
            |f^k(\textbf{x}) - f^k(\textbf{t})| \le L^k || \textbf{x} - \textbf{t} ||,\;\; k=1,...,n, 
        \end{equation}
        for $\textbf{x} \in A$, $\textbf{t} \in A$. Here $|| \cdot ||$ is usually \textit{Euclidean distance}, but
        other distance norms can also be used, e.g. \textit{city-block distance} is
        used in \cite{bbCB}. Lipschitz condition with respect to Euclidean
        distance is used in this paper. 
    \end{block}
      \vskip2ex
    \end{column}

    \begin{column}{\sepwid}\end{column}			% empty spacer column
    \begin{column}{\twocolwid}							% create a two-column-wide column and then we will split it up later
      \begin{columns}[t,totalwidth=\twocolwid]	% split up that two-column-wide column
        \begin{column}{\onecolwid}\vspace{-.69in}
    \begin{block}{Univariate one-step worst-case optimal algorithm}
        %%% Introduce the univariate concept
        \textit{The one-step worst-case optimal algorithm for bi-objective univariate
        optimization} introduced in \cite{ub} uses \textbf{tolerance} (also
        called \textbf{tightness} \cite{bbCB}) to bound
        the error of Pareto front approximation.
        The tolerance of the lower Lipschitz bound is defined as the maximum distance between local lower
        Lipschitz bound $V(f(x_1), f(x_2), x_1, x_2)$ and $\{f(x_1),
        f(x_2)\}$, $x_1 < x_2$ and it is denoted by
        \begin{multline}\label{tolerance}
            \Delta(f(x_1), f(x_2), x_1, x_2) = \\
            \max \left( \min_{\xi \in
                V(f(x_1),f(x_2), x_1, x_2)}\right. ||\xi - f(x_1)||,\\
                \left.\min_{\xi \in V(f(x_1), f(x_2), x_1, x_2)} ||\xi - f(x_2)||\right)
        \end{multline}

        The algorithm iteratively decreases the error of Pareto front 
        approximation by decreasing the tolerance $\Delta$. The algorithm stops
        when the maximum number of iterations $max\_iters$ is exceeded or the maximum
        of the tolerance is lower than predefined accuracy $\epsilon$. 
    \end{block}\vskip2ex
        \end{column}
        \begin{column}{\onecolwid}\vspace{-.69in}

        \begin{block}{Univariate algorithm adaptation for two variable problems}
            To use the univariate tolerance definition (\ref{tolerance}) for the
            bi-variate optimization problems we have to reduce two
            dimensional space, e.g. simplex, tolerance calculation to one
            dimensional tolerance calculation.

            The local lower Lipschitz bound for 2-simplex can be approximated
            by its longest edge local lower Lipschitz bound. This can be achieved
            by multiplying the actual Lipschitz constant $L^k$ by a constant
            $\hat{\alpha}^k$ before calculating the longest 2-simplex edge local lower
            Lipschitz bound, where $\hat{\alpha}^k$ is
            \begin{equation}
                \hat{\alpha}^k = \frac{b_3 + a_3 - 2 \underset{\textbf{x} \in ABC}{\min} \mathcal{L}^k(\textbf{x})}{L^k||A-B||}
            \end{equation}
            \begin{equation}
                \underset{\textbf{x} \in ABC}{\min} \mathcal{L}^k(\textbf{x}) = \max (AC' \cap Cone_B, BC' \cap Cone_A)
            \end{equation}
            \rmfamily{, here $Cone_A$, $Cone_B$ are cones constructed by Lipschitz
            lower bound drawn from vertices $A$, $B$. Here $AC'$, $BC'$ are
            generatrixes of $Cone_A$, $Cone_B$, which pass through $C$ point's
            projection $C'$ on to the cone's surface.}
        \end{block}
        \end{column}
      \end{columns}
      \vskip2.5ex

      \begin{alertblock}{Pseudocode}		% an ACTUAL two-column-wide column
          \begin{enumerate}
                \item Initialization: start by partitioning the feasible region
                    by simplices. Compute the function values at the simplex
                    vertices and the lower Lipschitz bound, compose the first
                    approximation of the Pareto front.
                \item Choose the candidate simplex with the largest tolerance
                    $\Delta$. If the tolerance is smaller than $\epsilon$, stop.
                \item Divide the chosen simplex into two smaller simplex by
                    dividing the longest edge.
                \item Compute the function value at new simplex vertex and the
                    Lower Lipschitz bounds, update the current approximation of
                    the Pareto front.
                \item If the predefined number of function evaluations is not
                    exceeded, return to Step 2. 
          \end{enumerate}
      \end{alertblock}

      \begin{columns}[t,totalwidth=\twocolwid]
        \begin{column}{\onecolwid}
        \begin{block}{Combinatorial triangulation of feasable region}
            Combinatorial triangulation was chosen for the proposed algorithm.
            This method is deterministic and based on
            enumeration of permutations of ${1, \dots, d }$. The number of
            simplices is known in advance and is equal to $d!$. For the higher
            dimension than 2 other triangulation methods should be chosen.
        \end{block}

        \end{column}
        \begin{column}{\onecolwid}

        \begin{block}{Experimental results}
        The experiments were made with bi-objective problem which
        has feasible region $[0,1]^2$ and Lipschitz constants $2, 1$:
        \begin{equation}
        \begin{array}{c}
            f^1(x_1, x_2) = ( x_1 - 1)x_2^2 + 1\\
            f^2(x_1, x_2) = x_2
        \end{array}
        \end{equation}
        , but experiments with greater objective
        function diversity should be made to get objective assesment. 
        \end{block}

      \end{column}
    \end{columns}
  \end{column}
  \begin{column}{\sepwid}\end{column}			% empty spacer column
  \begin{column}{\onecolwid}
     \begin{block}{Conclusions}
         One-step worst-case optimal bivariate algorithm for bi-objective
         optimization was proposed in this paper. It was shown
         that it is possible to generalise the one-step worst-case optimal
         univariate algorithm for the higher dimensional problems using
         Lipschitz condition with respect to Euclidean distance.  In addition,
         it was shown that partitioning by simplices can be used with the
         proposed algorithm. Thurthermore, the proposed algorithm has
         relatively smaller part of additional computations than the
         alternative bivariate algorithm \cite{bbCB}.
     \end{block}
     \vskip2ex
     \begin{block}{Future work}
         In the future work, the proposed algorithm should be generalized for a
         higher dimension and other feasable region triangulation methods should
         be analysed. The benefits of hyper-simplex approximation by a hyper-tetrahedron
         should be investigated. Also the proposed algorithms should be
         compared with other global optimization algorithms in more details.
     \end{block}
    \vskip2ex
    \begin{block}{References}
      \small{\rmfamily{\begin{thebibliography}{99}
      \bibitem{GlobalOptimization}
          Aimo Torn and Antanas \v{Z}ilinskas. \textit{Global optimization}.
          Springer-Verlag New York, Inc., 1989.
      \bibitem{ub}
          Antanas \v{Z}ilinskas. A one-step worst-case optimal algorithm for
          bi-objective univariate optimization. \textit{Optimization Letters},
          pages 1-16, 2013.
      \bibitem{bbCB}
          Antanas \v{Z}ilinskas and Julius \v{Z}ilinskas. Adaptation of a
          one-step worst-case optimal univariate algorithm of bi-objective
          Lipschitz optimization to multidimenstional problems.
          \textit{Communications in Nonlinear Science and Numerical
          Simulation}, 2014. 
      \bibitem{GlobalSimplicialOptimization}
          Remigijus Paulavi\v{c}ius and Julius \v{Z}ilinskas. \textit{Simplicial Global
          Optimization}. Springer, 2014.
      \end{thebibliography}}}
    \end{block}
    \vskip2ex

    \begin{block}{Acknowledgements}
      \rmfamily{The author is very grateful for his Ph.D. supervisor
      Antanas \v{Z}ilinskas for his valuable advices and insights.} \\
      \vspace{0.2in}
    \end{block}
  \end{column}
  \begin{column}{\sepwid}\end{column}			% empty spacer column
 \end{columns}
\end{frame}
\end{document}
